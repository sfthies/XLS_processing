{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for automatic merging of Mozambique data\n",
    "\n",
    "Some code to process XLS data and merge it into an appropriate format.\n",
    "\n",
    "**After longer work on this - retreat! - do manual merging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "import unidecode\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C://Users//wb555300//OneDrive - WBG//Municipality_merge//Source_tables\"\n",
    "os.chdir(file_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to check if format is xls:\n",
    "def is_xls(files):\n",
    "    xls_format = []\n",
    "    for x in files:\n",
    "        leng = len(x.strip().split(\".\"))\n",
    "        xls_format.append(x.strip().split(\".\")[leng-1]==\"xls\")\n",
    "    return np.array(xls_format)\n",
    "\n",
    "\n",
    "# split at multiple different seperators:\n",
    "def multi_split(txt, seps):\n",
    "    default_sep = seps[0]\n",
    "\n",
    "    # we skip seps[0] because that's the default separator\n",
    "    for sep in seps[1:]:\n",
    "        txt = txt.replace(sep, default_sep)\n",
    "    return [i.strip() for i in txt.split(default_sep)]\n",
    "\n",
    "\n",
    "## Functions to identify non-empty rows and columns:\n",
    "\n",
    "def nonempty_rows(sheet):\n",
    "    empty_row = []\n",
    "    for row in range(sheet.nrows):\n",
    "        empty_row.append(all(np.array(sheet.row_values(row,0))==''))\n",
    "    return np.where(np.array(empty_row)==False)[0]\n",
    "\n",
    "def nonempty_cols(sheet):\n",
    "    empty_col = []\n",
    "    for col in range(sheet.ncols):\n",
    "        empty_col.append(all(np.array(sheet.col_values(col,0))==''))\n",
    "    return np.where(np.array(empty_col)==False)[0]\n",
    "\n",
    "# Code to open a respective table:\n",
    "def open_table(muni, table, path):\n",
    "    path_loc = path + muni + '_Table_' + str(table) +'.csv'\n",
    "    return pd.read_csv(path_loc, index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make list with all files in directory\n",
    "all_files = np.array(os.listdir())\n",
    "xls_files = all_files[is_xls(all_files)]\n",
    "print(xls_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_files[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all tables from one file:\n",
    "\n",
    "Extract current municipality name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_loc = 'C:/Users/wb555300/OneDrive - WBG/Municipality_merge/Version2/'\n",
    "\n",
    "## Save list with problematic files\n",
    "problem_files = []\n",
    "\n",
    "## List with municipalities:\n",
    "munis = []\n",
    "# and available municipalities\n",
    "munis_avail = []\n",
    "\n",
    "\n",
    "for file in xls_files:\n",
    "\n",
    "    #Extract muni name:\n",
    "    muni_name = multi_split(file, seps = [\" \", \"_\", \".\"])[0]\n",
    "    munis.append(muni_name)\n",
    "    print('Currently processing data on: ', muni_name)\n",
    "    \n",
    "    #Open file:\n",
    "    wb = xlrd.open_workbook(file)\n",
    "    sheet = wb.sheet_by_index(0) \n",
    "\n",
    "    # Extract number of rows and columns in file:\n",
    "    ne_rows = nonempty_rows(sheet)\n",
    "    ne_cols = nonempty_cols(sheet)\n",
    "\n",
    "    # identify rows and columns where table starts (all tables tart with DESCRICAO):\n",
    "    start_rowcol = []\n",
    "\n",
    "    for row in ne_rows:\n",
    "        for col in ne_cols:\n",
    "            if(sheet.cell_value(row, col)==\"DESCRICAO\"): \n",
    "                start_rowcol.append([row, col])\n",
    "\n",
    "\n",
    "    #Extract all tables:\n",
    "    table_count = 1\n",
    "\n",
    "    for c_start in start_rowcol:\n",
    "\n",
    "        year_row = c_start[0]\n",
    "        OE_row = c_start[0]+1\n",
    "\n",
    "        years = sheet.row_values(year_row, c_start[1]+1)\n",
    "        OEs = sheet.row_values(OE_row, c_start[1]+1)\n",
    "        OEs = list(map(lambda x: unidecode.unidecode(x), OEs))\n",
    "\n",
    "        # duplicate year vector:\n",
    "        for x in range(len(years)):\n",
    "            if years[x] == '':\n",
    "                years[x] = years[x-1]\n",
    "\n",
    "        i = 2\n",
    "        current_rowname_start = multi_split(sheet.cell_value(c_start[0]+i, c_start[1]), [\" \", \"_\", \".\"])[0]\n",
    "\n",
    "        temp_df = pd.DataFrame({'muni': np.repeat(muni_name, len(years)),'year': np.array(years), 'OE': np.array(OEs)})\n",
    "        temp_df_cols = 3\n",
    "\n",
    "        while current_rowname_start != \"TOTAL\":\n",
    "            current_rowname_start = multi_split(sheet.cell_value(c_start[0]+i, c_start[1]), [\" \", \"_\", \".\"])[0]\n",
    "            if sheet.cell_value(c_start[0]+i, c_start[1]-1)!='':\n",
    "                temp_num = sheet.cell_value(c_start[0]+i, c_start[1]-1)\n",
    "            temp_name = str(temp_num).replace('.','_')+'-'+unidecode.unidecode(sheet.cell_value(c_start[0]+i, c_start[1])).upper().strip().replace(\"  \",\" \").replace(\" \", \"_\").replace(\",\", \"_\")\n",
    "            temp_values = sheet.row_values(c_start[0]+i, c_start[1]+1)\n",
    "                      \n",
    "            temp_df.insert(temp_df_cols, temp_name, temp_values, True)\n",
    "\n",
    "            temp_df_cols = temp_df_cols +1\n",
    "            i = i+1\n",
    "\n",
    "        csv_file_path = out_loc + muni_name + '_Table_' + str(table_count) +'.csv'\n",
    "    \n",
    "        temp_df.to_csv(csv_file_path)\n",
    "        table_count = table_count + 1\n",
    "     \n",
    "    if table_count-1 != 3: \n",
    "        print(colored(str(table_count-1) + ' tables found \\n', color='red'))\n",
    "        problem_files.append(file)\n",
    "    else:     \n",
    "        print(colored(str(table_count-1) + ' tables found \\n'))\n",
    "        munis_avail.append(muni_name)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Problem files: \", [multi_split(file, seps = [\" \", \"_\", \".\"])[0] for file in problem_files] ,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simply merge tables:\n",
    "In the following all tables are merged independently of similar column names. The code to replace similar column names can be found below... It was not used in the end as there were too many similarities in column names that needs to be judged on a one by one basis.\n",
    "\n",
    "#### Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_table_1 = open_table(munis_avail[0],1, path = out_loc)\n",
    "\n",
    "for muni in munis_avail:\n",
    "    print(\"processing \" + muni)\n",
    "    temp_table = open_table(muni,1, out_loc).iloc[0:14]\n",
    "    #temp_table = trans_similar_columns(overview_table_1, temp_table)\n",
    "    overview_table_1 = overview_table_1.append(temp_table, sort = False)\n",
    "    print(\"\\n\")\n",
    "\n",
    "overview_table_1.to_csv(\"../Overview/Table_1/Overview_Table_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_table_2 = open_table(munis_avail[0],2, path = out_loc)\n",
    "\n",
    "for muni in munis_avail[1:]:\n",
    "    print(\"processing \" + muni)\n",
    "    temp_table = open_table(muni,2, out_loc).iloc[0:14]\n",
    "    #temp_table = trans_similar_columns(overview_table_1, temp_table)\n",
    "    overview_table_2 = overview_table_2.append(temp_table, sort = False)\n",
    "    print(\"\\n\")\n",
    "\n",
    "overview_table_2.to_csv(\"../Overview/Table_2/Overview_Table_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_table_3 = open_table(munis_avail[0],3, path = out_loc)\n",
    "\n",
    "for muni in munis_avail[1:]:\n",
    "    print(\"processing \" + muni)\n",
    "    temp_table = open_table(muni,3, out_loc).iloc[0:14]\n",
    "    #temp_table = trans_similar_columns(overview_table_3, temp_table)\n",
    "    overview_table_3 = overview_table_3.append(temp_table, sort = False)\n",
    "    print(\"\\n\")\n",
    "\n",
    "overview_table_3.to_csv(\"../Overview/Table_3/Overview_Table_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More automation by automatic column name replacement (NOT USED):\n",
    "\n",
    "Function to replace similar column names - only if initial identifier agrees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_similar_columns(df1, df2, threshold = 0.8, trace = True):\n",
    "    ### Function compares column names of df2 with the names of df1 and replaces \n",
    "    ### names in df2 with the names of df1 if they are sufficiently similar!\n",
    "\n",
    "    col1 = list(df1.columns)[3:]\n",
    "    col2 = list(df2.columns)[3:]\n",
    "\n",
    "    col2_new = col2.copy()\n",
    "\n",
    "    for i2 in range(len(col2)):\n",
    "        #Iterate through columns of the existing data frame:\n",
    "\n",
    "        indicator1 = np.array([(col2_new[i2].split(\"-\")[0] == col1[i1].split(\"-\")[0]) for i1 in range(len(col1))])\n",
    "        indicator2 = np.array([difflib.SequenceMatcher(lambda z: z == \" \", (col2_new[i2].split(\"-\"))[1],col1[i1].split(\"-\")[1]).ratio() for i1 in range(len(col1))])        \n",
    "        indicator_t = indicator1*indicator2 > threshold \n",
    "\n",
    "        if any(indicator_t):\n",
    "            indi = int(np.where(indicator2 == indicator2.max())[0][0])\n",
    "            col2_new[i2] = col1[indi]\n",
    "            if indicator2.max() != 1 and trace == True:\n",
    "                print(col2_new[i2], 'was replaced with', col1[indi])\n",
    "        else:\n",
    "            temp = np.where(indicator2 == indicator2.max())[0][0]\n",
    "            indi = int(temp)\n",
    "            if trace == True:\n",
    "                print(colored(str(col2_new[i2])+' has highest similarity of '+ str(indicator2.max().round(2)) +' with ' + str(col1[indi]), color = \"red\"))\n",
    "\n",
    "    df2.columns = list(df2.columns)[:3]+col2_new\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge all Data Frames\n",
    "\n",
    "# ERRORS OCCUR DUE TO DUPLICATE COLUMN NAMES\n",
    "\n",
    "overview_table_1 = open_table(munis_avail[0],1, path = out_loc)\n",
    "\n",
    "for muni in munis_avail:\n",
    "    print(\"processing \" + muni)\n",
    "    temp_table = open_table(muni,1, out_loc).iloc[0:14]\n",
    "    temp_table = trans_similar_columns(overview_table_1, temp_table)\n",
    "    overview_table_1 = overview_table_1.append(temp_table, sort = False)\n",
    "    print(\"\\n\")\n",
    "\n",
    "overview_table_1.to_csv(\"../Overview/Table_1/Overview_Table_1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xls",
   "language": "python",
   "name": "xls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
